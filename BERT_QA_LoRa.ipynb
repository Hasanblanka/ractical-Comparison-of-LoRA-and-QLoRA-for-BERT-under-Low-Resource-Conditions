{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad138bfc-0a90-4bf9-b00f-f00421aa47a8",
   "metadata": {},
   "source": [
    "***Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210745e0-e50b-4ebb-b950-019157da6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "from datasets import Dataset,load_dataset,DatasetDict\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "import evaluate\n",
    "from evaluate import evaluator\n",
    "import seqeval\n",
    "from transformers import pipeline, AutoTokenizer,AutoModelForSequenceClassification,Trainer,TrainingArguments,DataCollatorWithPadding\n",
    "from transformers import AutoModelForQuestionAnswering,BitsAndBytesConfig,AutoModelForTokenClassification,default_data_collator\n",
    "from peft import LoraConfig,get_peft_model,TaskType,PeftModel,prepare_model_for_kbit_training\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "metric_accuracy = evaluate.load('accuracy')\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_seqeval = evaluate.load(\"seqeval\") \n",
    "metric_squad = evaluate.load(\"squad\")\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bbfa062-5655-4454-a084-76d7c7f8d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81491d61-3c08-442b-a785-9ee324c28d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7056083c-f263-4655-9459-ced710a82361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "589e16d1-c041-4cf4-85a7-3890c4786b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979f6f1-f720-424c-869d-6fec3ccad40a",
   "metadata": {},
   "source": [
    "***BERT-PEFT-LORA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e37d80a-319c-40c8-b6ad-79a13660007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"squad\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "low_resource_samples = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f681c8-2ff3-4552-b9f7-9f51a70b472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocess_qa_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    contexts = [c.strip() for c in examples[\"context\"]]\n",
    " \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, (answer, context) in enumerate(zip(examples[\"answers\"], contexts)):\n",
    "        \n",
    "        answer_text = answer[\"text\"][0]\n",
    "        answer_start = answer[\"answer_start\"][0]\n",
    "        answer_end = answer_start + len(answer_text)\n",
    "        \n",
    "   \n",
    "        if answer_text.lower() in context[answer_start:answer_end].lower():\n",
    "            \n",
    "            tokenized_context = tokenizer(context, add_special_tokens=False)\n",
    "            answer_tokens = tokenizer(answer_text, add_special_tokens=False)[\"input_ids\"]\n",
    "            found = False\n",
    "            \n",
    "            for j in range(len(tokenized_context[\"input_ids\"]) - len(answer_tokens) + 1):\n",
    "                if tokenized_context[\"input_ids\"][j:j+len(answer_tokens)] == answer_tokens:\n",
    "                    start_positions.append(j + 1)\n",
    "                    end_positions.append(j + len(answer_tokens))\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "        else:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e963503-d99b-4e4e-bc87-a68a0a15bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "train_dataset_small = dataset[\"train\"].select(range(512))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def simple_preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    contexts = [c.strip() for c in examples[\"context\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, answer in enumerate(examples[\"answers\"]):\n",
    "      \n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "\n",
    "tokenized_train = train_dataset_small.map(simple_preprocess_function, batched=True)\n",
    "tokenized_eval = dataset[\"validation\"].map(simple_preprocess_function, batched=True)\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.QUESTION_ANS\n",
    ")\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qa_lora_simple\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_qa_lora_simple\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "401510e7-8f12-4b0c-8571-ff703312e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 9:16:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=192, training_loss=0.6925157654786744, metrics={'train_runtime': 33396.3408, 'train_samples_per_second': 0.046, 'train_steps_per_second': 0.006, 'total_flos': 302584822235136.0, 'train_loss': 0.6925157654786744, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b98583b-e466-4c97-a1d9-44498a927e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./Bert_QA_LoRa_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10990f-9a3a-460e-bd30-f7d387a55074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31aebcb-8524-4c91-ba0d-d2aaa7d4406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298f8f2-162b-41af-ab2e-ec1c8157d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083639a4-7f22-4a14-86c5-7c0cd0b733cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474f0fd-fc5e-411c-8238-b634d13d44ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4f41d-5661-4c1f-ad43-3b2aaf8f326c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273153c2-dc9e-4c90-8541-cb08f20f95e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16384244-673c-431e-b7cf-f74cd794808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
